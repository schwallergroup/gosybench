{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda3/envs/jasyntho/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from jasyntho import SynthTree\n",
    "from jasyntho.extract import ExtractReaction\n",
    "\n",
    "async def extract_tree(path, model='gpt-3.5-turbo', method='text'):\n",
    "    tree = SynthTree.from_dir(path)\n",
    "    tree.rxn_extract = ExtractReaction(llm=model)\n",
    "\n",
    "    tree.raw_prods = await tree.async_extract_rss(mode=method)\n",
    "    tree.products = [p for p in tree.raw_prods if not p.isempty()]\n",
    "\n",
    "    reach_sgs = tree.partition()\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth graph\n",
    "import networkx as nx\n",
    "\n",
    "path = '../benchmark/papers/ja074300t'\n",
    "with open(os.path.join(path, 'gt_graph.pickle'), 'rb') as f:\n",
    "    gt_G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a graph from paper\n",
    "\n",
    "# tree = await extract_tree(path, model='gpt-3.5-turbo', method='vision')\n",
    "# extracted_G = tree.full_g\n",
    "\n",
    "# with open(os.path.join(path, 'extracted_graph_gpt35_vision.pickle'), 'wb') as f:\n",
    "#     pickle.dump(extracted_G, f)\n",
    "\n",
    "with open(os.path.join(path, 'extracted_graph_gpt35_vision.pickle'), 'rb') as f:\n",
    "    extracted_G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways of comparing the two graphs\n",
    "\n",
    "- Graph Edit Distance  # very slow\n",
    "- Subgraph matching\n",
    "- Spectral analysis\n",
    "- Edge overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorts of subgraph matching\n",
    "\n",
    "# Find subgraphs of extracted graph, and compare with ground truth graph\n",
    "def find_subgraphs_larger_than_n(G, N):\n",
    "    subgraphs = []\n",
    "    \n",
    "    # Find all connected components (subgraphs) in the graph\n",
    "    connected_subgraphs = nx.connected_components(G)\n",
    "    \n",
    "    # Iterate over each connected subgraph\n",
    "    for subgraph_nodes in connected_subgraphs:\n",
    "\n",
    "        # Check if the size of the subgraph is greater than N\n",
    "        if len(subgraph_nodes) > N:\n",
    "            # Create a subgraph from the nodes\n",
    "            subgraph = G.subgraph(subgraph_nodes)\n",
    "            subgraphs.append(subgraph)\n",
    "    \n",
    "    return subgraphs\n",
    "\n",
    "# Find subgraphs of size greater than 3\n",
    "N = 3\n",
    "subg_3 = find_subgraphs_larger_than_n(extracted_G.to_undirected(), N)\n",
    "\n",
    "\n",
    "def subgraph_in_gt(subgraph, gt_G):\n",
    "    # Check if the subgraph is present in the host graph\n",
    "    matcher = nx.algorithms.isomorphism.GraphMatcher(gt_G, subgraph)\n",
    "    is_match = matcher.subgraph_is_isomorphic()\n",
    "\n",
    "    if is_match:\n",
    "        print(\"The subgraph is present in the host graph.\")\n",
    "        # Get the mapping of nodes between the subgraph and the host graph\n",
    "        mapping = matcher.mapping\n",
    "        print(\"Mapping:\", mapping)\n",
    "    else:\n",
    "        print(\"The subgraph is not present in the host graph.\")\n",
    "\n",
    "for subgraph in subg_3:\n",
    "    subgraph_in_gt(subgraph, gt_G.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the immediate neighborhood of the nodes. e.g. is the local structure preserved?\n",
    "\n",
    "def get_neighborhood_subgraph(G, node):\n",
    "    # Get the incoming and outgoing neighbors of the node\n",
    "    in_neighbors = [edge[0] for edge in G.in_edges(node)]\n",
    "    out_neighbors = [edge[1] for edge in G.out_edges(node)]\n",
    "    neighbors = set(in_neighbors + out_neighbors + [node])\n",
    "    subgraph = G.subgraph(neighbors)\n",
    "    return subgraph\n",
    "\n",
    "def subgraph_in_gt_exact(subgraph, gt_G):\n",
    "    \"\"\"Check if the subgraph is present in the host graph.\"\"\"\n",
    "    subg_gt = gt_G.subgraph(subgraph.nodes)\n",
    "    if len(subg_gt) == len(subgraph):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def subgraph_in_gt_isomorphic(subgraph, gt_G):\n",
    "    matcher = nx.algorithms.isomorphism.GraphMatcher(gt_G, subgraph)\n",
    "    is_match = matcher.subgraph_is_isomorphic()\n",
    "    return is_match\n",
    "\n",
    "def compare_local_exact_0(G, gt_G):\n",
    "    quant = []\n",
    "    for node in G.nodes:\n",
    "        sg = get_neighborhood_subgraph(G, node)\n",
    "        if len(sg)>1:\n",
    "            v = subgraph_in_gt_exact(sg, gt_G)\n",
    "            quant.append(v)\n",
    "    return sum(quant)/len(quant)\n",
    "    \n",
    "def compare_local_exact(G, gt_G):\n",
    "    c1 = compare_local_exact_0(gt_G, G)\n",
    "    c2 = compare_local_exact_0(G, gt_G)\n",
    "    return c1, c2\n",
    "\n",
    "def compare_local_iso(G, gt_G):\n",
    "    quant = []\n",
    "    for node in G.nodes:\n",
    "        sg = get_neighborhood_subgraph(G, node)\n",
    "        if len(sg)>1:\n",
    "            v = subgraph_in_gt_isomorphic(sg, gt_G)\n",
    "            quant.append(v)\n",
    "    return sum(quant)/len(quant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0)\n",
      "(0.3471502590673575, 0.18584070796460178)\n",
      "(0.0, 0.007874015748031496)\n",
      "(0.0051813471502590676, 0.011904761904761904)\n"
     ]
    }
   ],
   "source": [
    "print(compare_local_exact(gt_G, gt_G))\n",
    "print(compare_local_exact(extracted_G, gt_G))\n",
    "\n",
    "# Compare with other syntheses\n",
    "path2 = '../benchmark/papers/jacs.0c00308'\n",
    "with open(os.path.join(path2, 'gt_graph.pickle'), 'rb') as f:\n",
    "    other_G = pickle.load(f)\n",
    "    print(compare_local_exact(other_G, gt_G))\n",
    "path2 = '../benchmark/papers/jacs.0c00363'\n",
    "with open(os.path.join(path2, 'gt_graph.pickle'), 'rb') as f:\n",
    "    other_G = pickle.load(f)\n",
    "    print(compare_local_exact(other_G, gt_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0)\n",
      "(0.1385886840432295, 0.39069250709788916)\n",
      "(0.00035056967572304995, 0.0)\n",
      "(0.0034423407917383822, 0.00037032465127762005)\n"
     ]
    }
   ],
   "source": [
    "# Similar thing, but with paths (testing more long-range structure)\n",
    "\n",
    "def get_paths(G):\n",
    "    paths = []\n",
    "    for n0 in G.nodes:\n",
    "        for n1 in G.nodes:\n",
    "            if n0 != n1:\n",
    "                if nx.has_path(G, n0, n1):\n",
    "                    ps = nx.all_simple_paths(G, source=n0, target=n1)\n",
    "                    paths += list(ps)\n",
    "    return paths\n",
    "\n",
    "def compare_path_exact_0(G, gt_G):\n",
    "    quant = []\n",
    "    subgraphs = get_paths(G)\n",
    "    for path in subgraphs:\n",
    "        if len(path)>1:\n",
    "            sg = G.subgraph(path)\n",
    "            v = subgraph_in_gt_exact(sg, gt_G)\n",
    "            quant.append(v)\n",
    "    return sum(quant)/len(quant)\n",
    "\n",
    "def compare_path_exact(G, gt_G):\n",
    "    c0 = compare_path_exact_0(G, gt_G)\n",
    "    c1 = compare_path_exact_0(gt_G, G)\n",
    "    return c0, c1\n",
    "\n",
    "\n",
    "print(compare_path_exact(gt_G, gt_G))\n",
    "print(compare_path_exact(extracted_G, gt_G))\n",
    "\n",
    "# Compare with other syntheses\n",
    "path2 = '../benchmark/papers/jacs.0c00308'\n",
    "with open(os.path.join(path2, 'gt_graph.pickle'), 'rb') as f:\n",
    "    other_G = pickle.load(f)\n",
    "    print(compare_path_exact(other_G, gt_G))\n",
    "path2 = '../benchmark/papers/jacs.0c00363'\n",
    "with open(os.path.join(path2, 'gt_graph.pickle'), 'rb') as f:\n",
    "    other_G = pickle.load(f)\n",
    "    print(compare_path_exact(other_G, gt_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO next: compare routes extracted with different methods! see if they make sense\n",
    "\n",
    "async def extractg(path, model='gpt-3.5-turbo', method='text'):\n",
    "\n",
    "    tree = await extract_tree(path, model=model, method=method)\n",
    "    extracted_G = tree.full_g\n",
    "\n",
    "    if model=='gpt-3.5-turbo':\n",
    "        k = \"gpt35\"\n",
    "    elif model=='gpt-4-turbo':\n",
    "        k = \"gpt4t\"\n",
    "    elif model=='gpt-4':\n",
    "        k = \"gpt4\"\n",
    "    elif model=='gpt-4o':\n",
    "        k = \"gpt4o\"\n",
    "\n",
    "    with open(os.path.join(path, f'extracted_graph_{k}_{method}.pickle'), 'wb') as f:\n",
    "        pickle.dump(extracted_G, f)\n",
    "\n",
    "    return extracted_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found key 'SI-7' in multiple children.\n",
      "Found key 'SiO2' in multiple children.\n",
      "Found key 'SiO2' in multiple children.\n",
      "Found key 'NaHMDS' in multiple children.\n",
      "Found key 'THF' in multiple children.\n",
      "Found key 'THF' in multiple children.\n",
      "\u001b[93mTotal paragraphs: 87\u001b[39m\n",
      "\u001b[93mProcessed paragraphs: 53\u001b[39m\n",
      "\u001b[93mFound 39 empty paragraphs.\u001b[39m\n",
      "\u001b[93m\tValidation error.: 2\u001b[39m\n",
      "\u001b[93m\tNo product found: 37\u001b[39m\n",
      "(0.5382059800664452, 0.18219972842858906)\n",
      "Found key '99' in multiple children.\n",
      "Found key 'SI-7' in multiple children.\n",
      "\u001b[93mTotal paragraphs: 87\u001b[39m\n",
      "\u001b[93mProcessed paragraphs: 65\u001b[39m\n",
      "\u001b[93mFound 25 empty paragraphs.\u001b[39m\n",
      "\u001b[93m\tNo product found: 25\u001b[39m\n",
      "(0.8092224231464737, 0.1575114183434144)\n",
      "Error in processing batch: Error code: 400 - {'error': {'message': 'Your input image may contain content that is not allowed by our safety system.', 'type': 'invalid_request_error', 'param': None, 'code': 'content_policy_violation'}}\n",
      "Error in processing batch: Error code: 400 - {'error': {'message': 'Your input image may contain content that is not allowed by our safety system.', 'type': 'invalid_request_error', 'param': None, 'code': 'content_policy_violation'}}\n",
      "Finished processing batch. Cost: 0.016395\n",
      "Finished processing batch. Cost: 0.021300000000000003\n",
      "Finished processing batch. Cost: 0.029610000000000004\n",
      "Finished processing batch. Cost: 0.031485\n",
      "Finished processing batch. Cost: 0.031215000000000003\n",
      "Finished processing batch. Cost: 0.03237\n",
      "Finished processing batch. Cost: 0.033525\n",
      "Finished processing batch. Cost: 0.033135000000000005\n",
      "Finished processing batch. Cost: 0.033030000000000004\n",
      "Finished processing batch. Cost: 0.029220000000000003\n",
      "Finished processing batch. Cost: 0.033435000000000006\n",
      "Finished processing batch. Cost: 0.037485000000000004\n",
      "Finished processing batch. Cost: 0.033285\n",
      "Finished processing batch. Cost: 0.036390000000000006\n",
      "Finished processing batch. Cost: 0.036795\n",
      "Finished processing batch. Cost: 0.039885000000000004\n",
      "Finished processing batch. Cost: 0.039225\n",
      "Finished processing batch. Cost: 0.04474500000000001\n",
      "Finished processing batch. Cost: 0.03561\n",
      "Finished processing batch. Cost: 0.04542\n",
      "Finished processing batch. Cost: 0.04474500000000001\n",
      "Finished processing batch. Cost: 0.045225\n",
      "Finished processing batch. Cost: 0.045075000000000004\n",
      "Finished processing batch. Cost: 0.047745\n",
      "Finished processing batch. Cost: 0.04807500000000001\n",
      "Finished processing batch. Cost: 0.05011500000000001\n",
      "Finished processing batch. Cost: 0.059685\n",
      "Finished processing batch. Cost: 0.060555\n",
      "Finished processing batch. Cost: 0.065085\n",
      "Finished processing batch. Cost: 0.071775\n",
      "Found key 'N/A' in multiple children.\n",
      "Found key 'None' in multiple children.\n",
      "Found key 'SI-26' in multiple children.\n",
      "Found key 'N/A' in multiple children.\n",
      "Found key 'SI-24' in multiple children.\n",
      "Found key 'SI-28' in multiple children.\n",
      "Found key 'None' in multiple children.\n",
      "\u001b[93mTotal paragraphs: 185\u001b[39m\n",
      "\u001b[93mProcessed paragraphs: 182\u001b[39m\n",
      "\u001b[93mFound 8 empty paragraphs.\u001b[39m\n",
      "\u001b[93m\tValidation error.: 1\u001b[39m\n",
      "\u001b[93m\tNo product found: 7\u001b[39m\n",
      "(0.3122866894197952, 0.1088754474756203)\n",
      "Error in processing batch: Error code: 400 - {'error': {'message': 'Your input image may contain content that is not allowed by our safety system.', 'type': 'invalid_request_error', 'param': None, 'code': 'content_policy_violation'}}\n",
      "Error in processing batch: Error code: 400 - {'error': {'message': 'Your input image may contain content that is not allowed by our safety system.', 'type': 'invalid_request_error', 'param': None, 'code': 'content_policy_violation'}}\n",
      "Finished processing batch. Cost: 0.01374\n",
      "Finished processing batch. Cost: 0.023985000000000003\n",
      "Finished processing batch. Cost: 0.027360000000000002\n",
      "Finished processing batch. Cost: 0.027945000000000005\n",
      "Finished processing batch. Cost: 0.028650000000000002\n",
      "Finished processing batch. Cost: 0.025845000000000003\n",
      "Finished processing batch. Cost: 0.027825000000000003\n",
      "Finished processing batch. Cost: 0.026115000000000003\n",
      "Finished processing batch. Cost: 0.033060000000000006\n",
      "Finished processing batch. Cost: 0.027000000000000003\n",
      "Finished processing batch. Cost: 0.029715000000000005\n",
      "Finished processing batch. Cost: 0.03021\n",
      "Finished processing batch. Cost: 0.03660000000000001\n",
      "Finished processing batch. Cost: 0.03327\n",
      "Finished processing batch. Cost: 0.034245000000000005\n",
      "Finished processing batch. Cost: 0.037755000000000004\n",
      "Finished processing batch. Cost: 0.0354\n",
      "Finished processing batch. Cost: 0.039165000000000005\n",
      "Finished processing batch. Cost: 0.038505000000000005\n",
      "Finished processing batch. Cost: 0.046575000000000005\n",
      "Finished processing batch. Cost: 0.030720000000000004\n",
      "Finished processing batch. Cost: 0.03939\n",
      "Finished processing batch. Cost: 0.04956000000000001\n",
      "Finished processing batch. Cost: 0.050055\n",
      "Finished processing batch. Cost: 0.06330000000000001\n",
      "Finished processing batch. Cost: 0.06624000000000001\n",
      "Finished processing batch. Cost: 0.06375\n",
      "Finished processing batch. Cost: 0.07551000000000001\n",
      "Finished processing batch. Cost: 0.06883500000000001\n",
      "Finished processing batch. Cost: 0.07716\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "Found key 'A' in multiple children.\n",
      "\u001b[93mTotal paragraphs: 187\u001b[39m\n",
      "\u001b[93mProcessed paragraphs: 160\u001b[39m\n",
      "\u001b[93mFound 36 empty paragraphs.\u001b[39m\n",
      "\u001b[93m\tNo product found: 36\u001b[39m\n",
      "(0.5186567164179104, 0.158869275398099)\n"
     ]
    }
   ],
   "source": [
    "eg = await extractg(path, model='gpt-3.5-turbo', method='text')\n",
    "print(compare_path_exact(eg, gt_G))\n",
    "\n",
    "eg = await extractg(path, model='gpt-4-turbo', method='text')\n",
    "print(compare_path_exact(eg, gt_G))\n",
    "\n",
    "eg = await extractg(path, model='gpt-3.5-turbo', method='vision')\n",
    "print(compare_path_exact(eg, gt_G))\n",
    "\n",
    "eg = await extractg(path, model='gpt-4-turbo', method='vision')\n",
    "print(compare_path_exact(eg, gt_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-OdwtjV3T1Q1V8rXdcDPQT3BlbkFJPq3j4kgQtLbAFuaKzBW0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "def extract_subgraph(graph, start_node):\n",
    "    \"\"\"Use BFS to find all nodes reachable from start_node.\"\"\"\n",
    "    reachable_nodes = set(nx.bfs_tree(graph, start_node))\n",
    "    return graph.subgraph(reachable_nodes).copy()\n",
    "\n",
    "def plot_graph(G):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    pos = graphviz_layout(G, prog=\"dot\")\n",
    "    nx.draw(G, pos, with_labels=True, arrows=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "reach_sgs = SynthTree.get_reach_subgraphs(extracted_G)\n",
    "print(len(reach_sgs))\n",
    "\n",
    "# for g in reach_sgs.values():\n",
    "#     if len(g) > 1:\n",
    "#             plot_graph(g)\n",
    "#             print(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasyntho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
