{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96410427-d1c2-4c90-ade1-124d50965456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from rxn.chemutils.miscellaneous import canonicalize_any\n",
    "\n",
    "# Canonicalization utils\n",
    "from rxn.chemutils.utils import remove_atom_mapping\n",
    "from sklearn.utils import gen_batches\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c46496-c1cf-4e1e-9d34-466e6c59f854",
   "metadata": {},
   "source": [
    "# Mapping data to embeddings.\n",
    "\n",
    "We do both of these in batch but keeping an index, so we can map back to dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91521da2-0ba1-4340-a4f9-0655495073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load clean dataset from `00_preprocess.ipynb`\n",
    "with open(\"../../data/processed/sg_db_clean.bin\", \"rb\") as f:\n",
    "    sg_db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39146c-b549-4056-828d-56f6f6ff7cb0",
   "metadata": {},
   "source": [
    "## RXNFP mapping.\n",
    "\n",
    "We'll just use rxnfp (https://rxn4chemistry.github.io/rxnfp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84700364-c559-4430-9f19-2476618fe58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rxnfp.transformer_fingerprints import (\n",
    "    RXNBERTFingerprintGenerator,\n",
    "    generate_fingerprints,\n",
    "    get_default_model_and_tokenizer,\n",
    ")\n",
    "\n",
    "rxn_model, rxn_tokenizer = get_default_model_and_tokenizer()\n",
    "rxnfp_generator = RXNBERTFingerprintGenerator(rxn_model, rxn_tokenizer)\n",
    "\n",
    "\n",
    "def preproc_rxn(smi):\n",
    "    u = remove_atom_mapping(smi)\n",
    "    try:\n",
    "        return canonicalize_any(u)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def embed_rxns(rxns):\n",
    "    rxns_pc = [preproc_rxn(r) for r in rxns]\n",
    "    fp = rxnfp_generator.convert_batch(rxns_pc)\n",
    "    return torch.tensor(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa3268b-b914-4dfd-8b91-56735cc111f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f363789a54854d48b91710c25c435af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First select rxn_setup only\n",
    "sg_db_setup_d = {i: b for i, b in enumerate(sg_db) if b[\"sgm_cls\"] == \"reaction set-up\"}\n",
    "sg_db_setup = [b for b in sg_db_setup_d.values()]\n",
    "\n",
    "# Select a batch size\n",
    "bs = 2048\n",
    "\n",
    "batches = gen_batches(len(sg_db_setup), batch_size=bs)\n",
    "len_batch = len(sg_db_setup) // bs\n",
    "rxn_embeds = []\n",
    "for b in tqdm(batches, total=len_batch):\n",
    "    # Select only\n",
    "    sentences = [s[\"rxn_smi\"] for s in sg_db_setup[b]]\n",
    "    embeds = embed_rxns(sentences)\n",
    "    torch.cuda.empty_cache()\n",
    "    rxn_embeds.append(embeds)\n",
    "\n",
    "rxn_embeds = torch.concat(rxn_embeds)\n",
    "torch.save(rxn_embeds, \"../../data/rxn_embeds_clean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c266c6-ea6b-4812-85b1-35358cafc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_embeds = torch.load(\"../../data/rxn_embeds_clean.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c7deb-cbf3-4274-9b45-d2d2b397e057",
   "metadata": {},
   "source": [
    "---\n",
    "## Natural Language Embeddings. Here we use an opensource model\n",
    "\n",
    "From https://huggingface.co/spaces/mteb/leaderboard, it looks like `BAAI/bge-large-en-v1.5` is the best currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7138ba2-6282-4409-abc1-407e916360c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9575521fd324e91bf4537c06c19ecb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = \"cuda:0\"\n",
    "embedding_model = \"BAAI/bge-large-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model)\n",
    "model = AutoModel.from_pretrained(embedding_model).to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def embed_batch(sentences):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(\n",
    "        sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "\n",
    "    del model_output, encoded_input\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings.to(\"cpu\")\n",
    "\n",
    "\n",
    "bs = 512\n",
    "batches = gen_batches(len(sg_db), batch_size=bs)\n",
    "len_batch = len(sg_db) // bs\n",
    "\n",
    "segm_embeds = []\n",
    "for i, b in tqdm(enumerate(batches), total=len_batch):\n",
    "    # Sentences we want sentence embeddings for\n",
    "    sentences = [s[\"txt_sgm\"] for s in sg_db[b]]\n",
    "    embeds = embed_batch(sentences)\n",
    "    segm_embeds.append(embeds)\n",
    "\n",
    "segm_embeds = torch.concat(segm_embeds)\n",
    "torch.save(segm_embeds, \"../../data/processed/embeds/segment_embeds.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63d98d-6c61-4163-a1b8-e45b954768f1",
   "metadata": {},
   "source": [
    "## Finally, split the tensor into subsets, to save memory for next visualization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b780b927-3fe3-4eaf-bc15-d1e05d90f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_embeds = torch.load(\"../../data/processed/embeds/segment_embeds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bb8486-377a-432d-b0c4-55e5ee0ba12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eb180eebce4b88acc0d0a57c2aaa2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 921886.0 reaction set-ups\n",
      "torch.Size([921886, 1024])\n",
      "There are 787540.0 work-ups\n",
      "torch.Size([787540, 1024])\n",
      "There are 452965.0 purifications\n",
      "torch.Size([452965, 1024])\n",
      "There are 417692.0 analysiss\n",
      "torch.Size([417692, 1024])\n",
      "CPU times: user 7.37 s, sys: 12.3 s, total: 19.7 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate for each segment class\n",
    "sgm_cls = np.array([s[\"sgm_cls\"] for s in sg_db])\n",
    "del sg_db  # For memory\n",
    "\n",
    "classes = [\"reaction set-up\", \"work-up\", \"purification\", \"analysis\"]\n",
    "for i, cl in tqdm(enumerate(classes), total=len(classes)):\n",
    "    idx = np.ones(len(sgm_cls))\n",
    "    idx = np.where(np.array(sgm_cls) == cl, idx, 0)\n",
    "\n",
    "    print(f\"There are {idx.sum()} {cl}s\")\n",
    "    slice = segm_embeds[idx == 1]\n",
    "    print(slice.shape)\n",
    "\n",
    "    # Load subset and make map\n",
    "    cl = re.sub(\" |-\", \"_\", cl)\n",
    "    torch.save(slice, f\"../../data/processed/embeds/segm_embs_{cl}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84ed47-9159-4e4f-bbcc-1b761c293faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jasyntho",
   "language": "python",
   "name": "jasyntho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
